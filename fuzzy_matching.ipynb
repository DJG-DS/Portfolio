{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script aims to match the names in ONS's 'built up areas' lookup table with the town names found in various funds available to the subnational expenditure team. Once all required town names are matched, the final product from this script will be a lookup table of all the town names used in the funds, along with the ONS code and the official name given by ONS for that code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is achieved by first merging all the files, containing funding data, into one dataframe. This is then fuzzy matched against the ONS lookup table. A new dataframe is then created from the rows that didn't match, each row is then cleaned and ran through the fuzzy match algorithm again. This is merged with with the matched dataframe and saved as a csv file. The final step was to manually check any errors, as well as values that didn't get matched. This was done bu checking the town name in from the fund file and cross referencing this with the lookup table. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframe of town names that will be fuzzy matched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataframe containing town names that need to be matched\n",
    "df_0 = pd.read_csv('D:/Users/daniel.godden/Data/output/towns_fund.csv')\n",
    "df_0['town']=df_0['geography_name']\n",
    "df_0 = df_0['town']\n",
    "df_0.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataframe containing town names that need to be matched\n",
    "df_1 = pd.read_csv('D:/Users/daniel.godden/Data/output/future_high_street_fund.csv')\n",
    "df_1 = df_1['town']\n",
    "df_1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataframe containing town names that need to be matched\n",
    "df_2 = pd.read_csv('D:/Users/daniel.godden/Data/data/fuzzy/towns_from_internal_data.csv')\n",
    "df_2['town'] = df_2['town_or_high_street']\n",
    "df_2 = df_2['town']\n",
    "df_2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataframe containing town names that need to be matched\n",
    "df_3 = pd.read_csv('D:/Users/daniel.godden/Data/data/fuzzy/Towns Fund Expenditure Data - March 2023 - fhsf - clean.csv')\n",
    "df_3['town'] = df_3['geography_name']\n",
    "df_3 = df_3['town']\n",
    "df_3.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataframe containing town names that need to be matched\n",
    "df_4 = pd.read_csv('D:/Users/daniel.godden/Data/data/fuzzy/Towns Fund Expenditure Data - March 2023 - towns - clean.csv')\n",
    "df_4['town'] = df_4['geography_name']\n",
    "df_4 = df_4['town']\n",
    "df_4.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge into single dataframe\n",
    "df0 = pd.merge(df_0,df_1.drop_duplicates(), how='outer')\n",
    "df0 = pd.merge(df0,df_2.drop_duplicates(), how='outer')\n",
    "df0 = pd.merge(df0,df_3.drop_duplicates(), how='outer')\n",
    "df0 = pd.merge(df0,df_4.drop_duplicates(), how='outer')\n",
    "df0.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframe of lookup names for fuzzy matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lookup table\n",
    "df1 = pd.read_csv('D:/Users/daniel.godden/Data/data/fuzzy/Built-up_Areas_(December_2022)_Names_and_Codes_in_England_and_Wales.csv')\n",
    "df1['lookup_town_code'] = df1['BUA22CD']\n",
    "df1['lookup_town'] = df1['BUA22NM']\n",
    "df1 = df1[['lookup_town_code','lookup_town']]\n",
    "df1['lookup_town_index'] = df1.index\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a dataframe of town names and a dataframe of lookup town names, we can use fuzzy matching to compare them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data\n",
    "\n",
    "column1 = 'town'\n",
    "column2 = 'lookup_town'\n",
    "\n",
    "df0[column1] = df0[column1].str.lower().str.strip()\n",
    "df1[column2] = df1[column2].str.lower().str.strip()\n",
    "\n",
    "# Define a function to calculate the similarity score\n",
    "def fuzzy_match(row1, row2):\n",
    "    return fuzz.token_sort_ratio(row1[column1], row2[column2])\n",
    "\n",
    "# Calculate the similarity score for each pair of rows\n",
    "similarity_scores = []\n",
    "for i, row1 in df0.iterrows():\n",
    "    for j, row2 in df1.iterrows():\n",
    "        similarity_scores.append({\n",
    "            'town_index': i,\n",
    "            'lookup_town_index': j,\n",
    "            'score': fuzzy_match(row1, row2)\n",
    "        })\n",
    "\n",
    "# Convert the similarity scores to a dataframe\n",
    "similarity_df = pd.DataFrame(similarity_scores)\n",
    "\n",
    "# Merge the rows with a similarity score above a threshold\n",
    "threshold = 90\n",
    "matches = similarity_df[similarity_df['score'] >= threshold]\n",
    "matches.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create final dataframe for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF0 = pd.merge(df0,matches, on='town_index', how='inner')\n",
    "DF0 = pd.merge(df1,DF0, on='lookup_town_index', how='inner')\n",
    "DF0 = DF0.drop(['town_index','lookup_town_index'], axis=1)\n",
    "DF0.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe of the rows from 'df0' that dont match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF1 = pd.merge(df0,DF0.drop_duplicates(), on='town', how='left', indicator=True)\n",
    "non_match = DF1.loc[DF1['_merge']!= 'both']\n",
    "non_match = non_match.drop(['_merge'], axis=1)\n",
    "non_match = non_match['town']\n",
    "non_match.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_match['non_matched_town'] = non_match\n",
    "non_match['town'] = non_match['non_matched_town'].str.replace('city centre', '').str.replace('town centre','')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fuzzy match the non_match dataframe with df1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data\n",
    "\n",
    "column1 = 'town'\n",
    "column2 = 'lookup_town'\n",
    "\n",
    "non_match[column1] = non_match[column1].str.lower().str.strip()\n",
    "df1[column2] = df1[column2].str.lower().str.strip()\n",
    "\n",
    "# Define a function to calculate the similarity score\n",
    "def fuzzy_match(row1, row2):\n",
    "    return fuzz.token_sort_ratio(row1[column1], row2[column2])\n",
    "\n",
    "# Calculate the similarity score for each pair of rows\n",
    "similarity_scores = []\n",
    "for i, row1 in non_match.iterrows():\n",
    "    for j, row2 in df1.iterrows():\n",
    "        similarity_scores.append({\n",
    "            'town_index': i,\n",
    "            'lookup_town_index': j,\n",
    "            'score': fuzzy_match(row1, row2)\n",
    "        })\n",
    "\n",
    "# Convert the similarity scores to a dataframe\n",
    "similarity_df = pd.DataFrame(similarity_scores)\n",
    "\n",
    "# Merge the rows with a similarity score above a threshold\n",
    "threshold = 90\n",
    "matched = similarity_df[similarity_df['score'] >= threshold]\n",
    "matched.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF0 = pd.merge(DF0,matched, on='town_index', how='inner')\n",
    "DF0 = DF0.drop(['town_index','lookup_town_index'], axis=1)\n",
    "DF0.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the folder and file name to save the csv file\n",
    "folder_path = 'D:/Users/daniel.godden/Data/output'\n",
    "file_name = 'town_names_match.csv'\n",
    "\n",
    "DF0.to_csv(folder_path + '/' + file_name, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "caf831573a0ff294614842876d2763885d6da16fb80bd95fae4076843946dd1d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
